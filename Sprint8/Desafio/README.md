# Objetivo  
O objetivo √© praticar a combina√ß√£o de conhecimentos vistos no programa e fazer um mix de tudo que j√° foi dito.  

# Perguntas  

Aqui ser√£o analisadas perguntas referentes aos filmes e s√©ries dos g√™neros crime e/ou guerra.  

1. **Qual √© a distribui√ß√£o da nota m√©dia dos filmes e s√©ries por g√™nero crime/guerra?**  
**Motivo da an√°lise:** Pode ser um indicativo da prefer√™ncia do p√∫blico por um determinado formato de m√≠dia, al√©m de verificar se existe uma tend√™ncia √† filmes terem nota m√©dia maiores do que s√©ries ou vice-versa.  

2. **Existe uma correla√ß√£o entre a idade dos artistas e as notas m√©dias dos filmes e s√©ries em que atuaram?**  
**Motivo da an√°lise:** A an√°lise pode revelar se existe uma tend√™ncia de que atores mais jovens ou mais velhos tenham desempenho melhor, al√©m de poder, possivelmente, mostrar uma vis√£o sobre a import√¢ncia de diferentes faixas et√°rias nas ind√∫strias de filmes e s√©ries.  

3. **Como o tempo de dura√ß√£o dos filmes e das s√©ries se relaciona com a nota m√©dia e com o n√∫mero de votos?**  
**Motivo da an√°lise:** Perceber se existe alguma prefer√™ncia por filmes e s√©ries mais longos ou mais curtos.  

4. **Quais s√£o o filme e a s√©rie com maior n√∫mero de votos da √∫ltima d√©cada?**  
**Motivo da an√°lise:** verificar se existe rela√ß√£o entre os enredos e tamb√©m se possuem artistas em comum.  

5. **Quais artistas t√™m a maior nota m√©dia?**  
**Motivo da an√°lise:** Avaliar quais artistas s√£o mais frequentemente bem avaliados e montar um ranking, por exemplo, Top 5 Artistas mais bem avaliados das s√©ries e dos filmes.  

#

# Instru√ß√µes Gerais  
**Ingest√£o de API:**  
Nesta etapa do desafio iremos capturar dados do TMDB via AWS Lambda realizando chamadas de API.
Os dados coletados devem ser persistidos em Amazon S3, camada RAW Zone, mantendo o formato da origem (JSON) , agrupando-os
em arquivos com, no m√°ximo, 100 registros cada arquivo.

**Informa√ß√µes importantes:**  

- Os arquivos JSON gerados n√£o devem ter mais que 10MB  

- N√£o agrupar JSON com estruturas diferentes

- Os IDs do IMDB presentes nos arquivos CSV podem ser utilizados em pesquisas no TMDB  


**No servi√ßo AWS Lambda, realize os passos:**  

1. Se necess√°rio, criar nova camada (layer) no AWS lambda para as libs necess√°rias √† ingest√£o de dados (por exemplo, tmdbv3api, se utilizar o TMDB)

2. Implementar c√≥digo python em AWS lambda para consumo de dados do TMDB 

3. Se est√° utilizando TMDB, buscar pela API os dados que complementem a an√°lise. Se achar importante, agrupar os
retornos da API em arquivo JSON com, no m√°ximo, 100 registros cada.

4. Utilizar a lib boto3 para gravar os dados no AWS S3.
	- no momento da grava√ß√£o dos dados deve-se considerar o padr√£o do path:
	desafio-final-pb-welder\Raw\TMDB\JSON\<data_de_processamento_separada_por_ano\mes\dia>\<arquivo>
	
	exemplos:
	- S3:\\data-lake-do-fulano\Raw\TMDB\JSON\2022\05\02\prt-uty-nfd.json
	- S3:\\data-lake-do-fulano\Raw\TMDB\JSON\2022\05\02\idf-uet-wqt.json   
	
**Informa√ß√£o adicional:**  
Podemos utilizar os servi√ßos do CloudWatch Event ou Amazon EventBridge para agendar extra√ß√µes peri√≥dicas de dados de 
forma autom√°tica.

# C√≥digos e Execu√ß√£o  
- Para fazer o envio dos arquivos ao bucket do S3 foram usadas as fun√ß√µes abaixo:
```python 
def enviar_arquivo(bucket_name, file_path, object_name, s3_client):
    try:
        s3_client.upload_file(file_path, bucket_name, object_name)
        print(f"Upload do arquivo '{object_name}' no Bucket '{bucket_name}' foi realizado com sucesso.")
    except FileNotFoundError:
        print(f"Erro: O arquivo '{file_path}' n√£o foi encontrado.")
    except ClientError as e:
        print(f"Erro ao enviar o arquivo para o S3: {e}")
    except Exception as exc:
        print(f"Erro inesperado: {exc}")
```
```python
def build_s3_path(file, bucket_name='desafio-final-pb-welder'):
    date = datetime.now()
    year = date.year
    month = date.month
    day = date.day
    path = f"Raw/TMDB/JSON/{year}/{month:02d}/{day:02d}/{file}"
    return path
```  

Para puxar os dados da API do TMDB foi usado o c√≥digo abaixo:  
```python 
def fetch_tmdb_data(api_key, media_type='movie', page=1, genres=[80, 10752]):
    all_results = []  # Lista para armazenar todos os resultados combinados
    
    for genre_id in genres:  # Iterar sobre os g√™neros especificados
        url = f'https://api.themoviedb.org/3/discover/{media_type}?api_key={api_key}&page={page}&with_genres={genre_id}'
        response = requests.get(url)
        
        if response.status_code == 200:
            all_results.extend(response.json().get('results', []))  # Adicionar os resultados √† lista
        else:
            print(f"Erro ao buscar dados do TMDB para o g√™nero {genre_id}: {response.status_code}")
    
    return all_results
```  

Por fim, a fun√ß√£o lambda_handler utilizada para rodar o c√≥digo na AWS:  
```python 
def lambda_handler(event, context):
    #vari√°veis de ambiente
    api_key = os.environ['TMDB_API_KEY']
    bucket_name = 'desafio-final-pb-welder'
    
    #inicializando client S3
    s3_client = boto3.client('s3')
    
    #tipos de m√≠dia (filmes e s√©ries)
    media_types = ['movie', 'tv']  # 'movie' para filmes e 'tv' para s√©ries
    
    #g√™neros de interesse (crime = 80, guerra = 10752)
    genres = [80, 10752]
    
    for media_type in media_types:
        all_data = []
        page = 1
                
        while True:
            data = fetch_tmdb_data(api_key, media_type, page, genres)
            if not data:  #caso n√£o haver mais dados, parar para evitar loop infinito.
                break
            all_data.extend(data)
            page += 1
        
        #dividindo o arquivo em subarquivos
        for idx, data_chunk in enumerate(dividir_json(all_data, max_registros=100)):
            #criando arquivo JSON tempor√°rio em /tmp
            file_name = f"/tmp/{media_type}_dados_{datetime.now().strftime('%Y%m%d%H%M%S')}_{idx + 1}.json"
            with open(file_name, 'w', encoding='utf-8') as f:
                json.dump(data_chunk, f, ensure_ascii=False, indent=4)
            
            s3_path = build_s3_path(file_name.split('/')[-1], bucket_name)
            
            enviar_arquivo(bucket_name, file_name, s3_path, s3_client)

            #removendo o arquivo local ap√≥s envio para o S3
            os.remove(file_name)
        
    return {
        'statusCode': 200,
        'body': json.dumps('Arquivos processados e enviados para o S3 com sucesso.')
    }
```

Para a execu√ß√£o correta do c√≥digo no AWS Lambda foi necess√°rio criar uma camada (layer) para a biblioteca **requests**.  
Para tal, foi criado um diret√≥rio requests e um subdiret√≥rio python, onde foi instalada a biblioteca atrav√©s do m√©todo pip install requests. Feito isso, a pasta foi zipada e feito o upload na plataforma AWS Lambda.  

Um ponto a ser destacado √© que, em rela√ß√£o √† sprint anterior, h√° uma pequena altera√ß√£o no script em rela√ß√£o √†s credenciais de acesso que n√£o s√£o mais necess√°rias, uma vez que j√° estamos em ambiente AWS. Por outro lado, foi necess√°rio criar um perfil de usu√°rio do IAM para permitir a manipula√ß√£o de arquivos em buckets S3 atrav√©s do lambda.

Outro ponto a ser destacado √© a configura√ß√£o da vari√°vel ambiente para a chave da API do TMDB como uma boa pr√°tica, para n√£o exp√¥r os dados no c√≥digo.

![desafio](../Evidencias/terminal_lambda.png)
![desafio](../Evidencias/desafio1.png)
![desafio](../Evidencias/desafio2.png)
![desafio](../Evidencias/desafio3.png)
![desafio](../Evidencias/desafio4.png)
![desafio](../Evidencias/desafio5.png)
![desafio](../Evidencias/desafio6.png)

# Links
[üìú**Certificados**](/Sprint7/Certificados/)  
[üïµÔ∏è‚Äç‚ôÇÔ∏è**Evid√™ncias** ](/Sprint7/Evidencias/)  
[üí™**Exerc√≠cios**](/Sprint7/Exercicios/)  
[üñ≥ **Desafio**](/Sprint7/Desafio/README.md)  